{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa16c9-2c8c-4bef-b238-2a8dcdec343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "INPUT_FILE = 'ilr_coordinates.csv'\n",
    "OUTPUT_FILE = 'final_cluster_labels.csv'\n",
    "PLOT_FILE = 'BIC_SCORE_PLOT.png'\n",
    "\n",
    "# The 4 Coordinates we calculated in Phase 2\n",
    "FEATURES = ['ilr_Activity', 'ilr_Profitability', 'ilr_Solvency', 'ilr_Liquidity_Texture']\n",
    "\n",
    "print(\"--- STARTING PHASE 3: BEHAVIORAL CLUSTERING (GMM) ---\")\n",
    "\n",
    "# 1. LOAD DATA\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "    print(f\"Loaded Data: {df.shape[0]} rows.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"CRITICAL ERROR: Could not find '{INPUT_FILE}'. Run Phase 2 first.\")\n",
    "    exit()\n",
    "\n",
    "# 2. PREPARE DATA\n",
    "# We filter for the features. We drop any remaining NaNs just in case (should be 0).\n",
    "X = df[FEATURES].dropna()\n",
    "companies_aligned = df.loc[X.index] # Keep metadata aligned\n",
    "\n",
    "# Standardize? \n",
    "# While CoDa is already normalized, scaling helps GMM converge faster.\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# =============================================================================\n",
    "# STEP A: FIND OPTIMAL CLUSTERS (BIC Score)\n",
    "# =============================================================================\n",
    "print(\"Calculating Optimal Number of Clusters (BIC)...\")\n",
    "# We test K=2 to K=20. The lower the BIC, the better the model fits the data.\n",
    "\n",
    "bic_scores = []\n",
    "k_range = range(2, 21)\n",
    "\n",
    "best_bic = np.inf\n",
    "best_k = 0\n",
    "\n",
    "for k in k_range:\n",
    "    # covariance_type='full' allows clusters to have different shapes (ellipses)\n",
    "    gmm = GaussianMixture(n_components=k, covariance_type='full', random_state=42, n_init=3)\n",
    "    gmm.fit(X_scaled)\n",
    "    \n",
    "    bic = gmm.bic(X_scaled)\n",
    "    bic_scores.append(bic)\n",
    "    \n",
    "    # Track best model\n",
    "    if bic < best_bic:\n",
    "        best_bic = bic\n",
    "        best_k = k\n",
    "    \n",
    "    print(f\"   K={k}: BIC={bic:.0f}\")\n",
    "\n",
    "print(f\"\\n-> OPTIMAL K FOUND: {best_k} Clusters (Lowest BIC)\")\n",
    "\n",
    "# Plot BIC for Thesis\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, bic_scores, marker='o', linestyle='-', color='b')\n",
    "plt.title('Optimal Cluster Selection (Bayesian Information Criterion)')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('BIC Score (Lower is Better)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axvline(best_k, color='r', linestyle='--', label=f'Optimal K={best_k}')\n",
    "plt.legend()\n",
    "plt.savefig(PLOT_FILE)\n",
    "print(f\"-> BIC Plot saved to '{PLOT_FILE}'\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP B: FIT FINAL MODEL\n",
    "# =============================================================================\n",
    "print(f\"Fitting Final GMM Model with K={best_k}...\")\n",
    "\n",
    "final_gmm = GaussianMixture(n_components=best_k, covariance_type='full', random_state=42, n_init=10)\n",
    "final_gmm.fit(X_scaled)\n",
    "\n",
    "# 1. Hard Assignment (The specific cluster ID)\n",
    "cluster_labels = final_gmm.predict(X_scaled)\n",
    "\n",
    "# 2. Soft Probability (For Reliance-style \"Hybrid\" Analysis)\n",
    "# How confident is the model? (Max probability)\n",
    "probs = final_gmm.predict_proba(X_scaled)\n",
    "max_probs = probs.max(axis=1)\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE OUTPUT\n",
    "# =============================================================================\n",
    "# Attach results back to the original dataframe\n",
    "# Note: We use .loc to ensure we match the indices correctly\n",
    "output_df = df.copy()\n",
    "output_df['Cluster_ID'] = np.nan\n",
    "output_df['Cluster_Prob'] = np.nan\n",
    "\n",
    "output_df.loc[X.index, 'Cluster_ID'] = cluster_labels\n",
    "output_df.loc[X.index, 'Cluster_Prob'] = max_probs\n",
    "\n",
    "# Save\n",
    "output_df.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"SUCCESS! Phase 3 Complete.\")\n",
    "print(f\"Generated {best_k} Behavioral Peer Groups.\")\n",
    "print(f\"Saved Clustered Data to: {OUTPUT_FILE}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Optional: Print Cluster Stats\n",
    "print(\"\\nCluster Distribution:\")\n",
    "print(output_df['Cluster_ID'].value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
